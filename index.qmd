# CAPSTONE PROJECT

## Machine Learning and Predictive Analytics for Heart Disease Prediction

### Introduction

#### Problem Defination

Heart disease is still one of the worst public health crises worldwide. The World Health Organization (WHO) reports that cardiovascular diseases claim approximately 17.9 million lives each year, which is almost one-third of all deaths on the planet. Despite tremendous advances in medicine, detection of heart disease at its early stage continues to be an issue. Interpretation by doctors of medical data such as ECG readings forms the cornerstone of traditional diagnosis, cholesterol level, and patient history, which in certain instances can lead to inconsistent or delayed conclusions.

In the last couple of years, the emergence of data science and machine learning has opened up new avenues to solve this problem. Machine learning algorithms have provided promising results in identifying patterns in medical data that are not apparent to the human eye. Predictive analytics can be used to forecast the risk of a patient developing heart disease based on multiple indicators. This can help health professionals with early identification, preventive measures, and resource planning. The main problem addressed in this research is how to build and evaluate a reliable machine learning model that can predict heart disease from patient health data with high accuracy and interpretability#### What problem or gap in the existing literature does the paper aim to address?

This study aims to address the systematic evaluation of explainability techniques in predictive process analytics, which has been recognized as an open problem. While the literature is such that quite a number of papers exist that are concerned with the improving predictive models or proposing new XAI methods, no standard evaluation frameworks have been developed to evaluate the methods in terms of reliability, stability, and fidelity. This study develops functionally-grounded evaluation metrics for measuring stability and fidelity of explanations produced by some of the popular XAI methods, namely LIME and SHAP, as well as checks whether these methods deliver consistent and faithful explanations for predictive process models constructed using XGBoost, a widely employed machine learning algorithm known for its high classification accuracy.

#### Context and Background

Predictive analytics and machine learning are core areas of data science that use statistical and computational methods to model and predict data. Predictive modeling in healthcare helps to establish disease risk factors, evaluate treatment outcomes, and support medical decision-making. Research has looked at the use of algorithms such as Logistic Regression, Decision Trees, Random Forest, and Neural Networks for medical prediction. These models rely based on mathematical functions to model health indicator-disease co-occurrence relationships.

Logistic Regression, for example, uses a sigmoid function to model probability of binary outcome (disease or no disease), while Decision Trees and Random Forests provide rule-based approaches that divide the data into more manageable pieces. Healthcare machine learning also involves advanced notions like feature engineering, dimensionality reduction, and hyperparameter tuning, which improve the precision and effectiveness of prediction models. This project utilizes these principles to develop a data-intensive approach to predict heart disease risk using open-source medical data.

#### Objective and Goals

The main objective of the project is to develop a machine learning model to predict heart disease with high accuracy and interpretability. The study objectives are as follows: 1. To collect, preprocess, and analyze a publicly available heart disease dataset. 2. To apply various machine learning algorithms—Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine (SVM)—and compare their performances. 3. To contrast models on the basis of statistical performance metrics such as accuracy, precision, recall, F1-score, and AUC. 4. To identify the most important health features for the prediction of heart disease. 5. To examine the practical implications of the results for the improvement of preventive healthcare practice.

By achieving the above goals, the study will demonstrate how data-driven modeling can assist healthcare professionals in making informed clinical choices and improving patient results.

#### Summary of Approach

This project follows a systematic machine learning pipeline right from data collection and preprocessing, to exploratory data analysis, feature selection, and model training. The research will use different classification algorithms and tune their parameters to provide the most predictive performance. The predictive performance of the models will be compared on key evaluation metrics. Visualizations will also be used to clarify model results and illustrate the impact of different features. The project combines statistical thinking, mathematical modeling, and computer science methodologies to create an integrated predictive framework for heart disease analysis.

### METHODS USED

#### Data Acquisition and Sources

The dataset employed in this project is the Cleveland Heart Disease Dataset, obtained from the UCI Machine Learning Repository, a well-established open-source platform for research data. This dataset is among the most widely used benchmarks for heart disease prediction studies. It consists of 303 patient records, each described by 14 attributesrepresenting various clinical, physiological, and demographic parameters. These include features such as age, sex, resting blood pressure, serum cholesterol level, fasting blood sugar, maximum heart rate achieved, chest pain type, exercise-induced angina, ST depression induced by exercise, and resting electrocardiographic results, among others. The target variable indicates the presence (1) or absence (0) of heart disease in the patient.

Prior to model development, several data preprocessing steps are performed to ensure data quality, consistency, and suitability for machine learning algorithms:

1.  **Handling Missing Values:**\
    Any records containing missing or null values are identified and treated appropriately. Depending on the degree of missingness, imputation techniques such as mean, median, or mode substitution may be applied, or rows with excessive missing information may be removed to maintain data integrity.

2.  **Data Cleaning and Outlier Detection:**\
    Outliers in continuous variables (e.g., blood pressure, cholesterol, or heart rate) are detected using statistical techniques such as the Interquartile Range (IQR) method or z-score analysis. Identified outliers are examined for plausibility and either corrected or removed to prevent distortion in model training.

3.  **Encoding Categorical Variables:**\
    Categorical features, such as gender, chest pain type (cp), resting ECG results (restecg), and thalassemia (thal), are transformed into numerical form using label encoding or one-hot encoding, depending on the nature of the category. This step allows machine learning algorithms to interpret categorical information effectively.

4.  **Feature Scaling:**\
    To bring all numerical variables onto a comparable scale, feature scaling is applied using techniques such as Min–Max Normalization or Standardization (Z-score scaling). This process ensures that attributes with large numerical ranges (e.g., cholesterol or maximum heart rate) do not dominate model learning.

5.  **Data Splitting:**\
    The dataset is divided into training and testing subsets using an 80:20 ratio, ensuring that model evaluation is conducted on unseen data to assess generalization performance. Additionally, k-fold cross-validation may be employed to enhance the reliability and stability of results.

6.  **Exploratory Data Analysis (EDA):**\
    Before model building, comprehensive EDA is conducted to understand the underlying data structure. Visualizations such as histograms, box plots, and pair plots are used to observe feature distributions, while correlation matrices and heatmaps help identify relationships among variables. This step provides valuable insights into which features are most strongly associated with heart disease occurrence.

All preprocessing, exploration, and model development are performed using Python in the Jupyter Notebook environment, leveraging powerful libraries including pandas, NumPy, matplotlib, and seaborn for data manipulation and visualization. This structured and systematic approach ensures that the dataset is clean, well-prepared, and optimized for building robust predictive models.

#### Mathematical and Statistical Models

Several supervised learning algorithms will be used to model the data. These include:

-   **Logistic Regression:** A statistical model that predicts the probability of heart disease occurrence based on a linear combination of input features.

$$
P(Y=1 \mid X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_n X_n)}}
$$

-   **Decision Tree Classifier:** A model that splits data into branches using decision rules, allowing for simple interpretation.

$$
G(S, A) = Entropy(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} \, Entropy(S_v)
$$

-   **Random Forest:** An ensemble model that combines multiple decision trees to improve accuracy and reduce overfitting.

$$
\hat{y} = \text{majority\_vote}\left( h_1(x), h_2(x), \dots, h_k(x) \right)
$$

-   **Support Vector Machine (SVM):** A classification model that finds an optimal hyperplane separating patients with and without heart disease.

$$
\min_{w, b} \ \frac{1}{2} \|w\|^2 \quad \text{subject to} \quad y_i (w^T x_i + b) \ge 1, \ \forall i
$$

Each of these algorithms uses mathematical and statistical principles for pattern recognition. Logistic regression uses maximum likelihood estimation; Decision Trees rely on information gain and Gini impurity; SVMs use kernel functions to map nonlinear data. Model selection and hyperparameter tuning will be done through grid search or cross-validation techniques.

#### ![](images/WhatsApp%20Image%202025-10-08%20at%2019.57.13.jpeg)

#### Experimental Design or Analytical Procedures

The workflow for this project includes several analytical stages. The dataset will be divided into training and testing subsets using an 80/20 ratio. Model training will occur on the training subset, and model testing will evaluate generalization on unseen data. Cross-validation (k-fold) will be performed to ensure that model results are not due to random splits. The models’ performance will be compared using metrics such as Accuracy, Precision, Recall, F1-score, and Area Under the ROC Curve (AUC). Confusion matrices and ROC curves will be generated for visualization.\

Feature importance will be analyzed to identify which attributes (such as cholesterol level, blood pressure, or age) contribute most significantly to predicting heart disease. Sensitivity analysis will also be performed to evaluate how small changes in inputs affect model predictions, ensuring robustness.\

| Variable | Description | Type | Example Value |
|------------------|------------------|------------------|-------------------|
| **age** | Age of the patient (in years) | Numeric | 54 |
| **sex** | Gender of the patient (1 = male, 0 = female) | Categorical | 1 |
| **cp** | Chest pain type (0–3, indicating severity/type) | Categorical | 2 |
| **trestbps** | Resting blood pressure (mm Hg) | Numeric | 130 |
| **chol** | Serum cholesterol level (mg/dl) | Numeric | 246 |
| **thalach** | Maximum heart rate achieved | Numeric | 150 |

#### Model Evaluation Metrics

The performance of each machine learning model was assessed using multiple **evaluation metrics**, ensuring a balanced understanding of predictive ability and model reliability:

-   **Accuracy** – Overall proportion of correct predictions.

-   **Precision** – Fraction of correctly predicted positive cases among all predicted positives.

-   **Recall (Sensitivity)** – Fraction of actual positives correctly identified by the model.

-   **F1-Score** – Harmonic mean of precision and recall, balancing both metrics.

-   **ROC Curve and AUC (Area Under the Curve)** – Graphical and numerical measures of model discrimination ability.

These metrics were used collectively to compare models and determine which algorithm performs best for heart disease prediction.\
\
Software and Tools

All computations will be performed using Python. The libraries and tools used include:

-   pandas and NumPy for data preprocessing and analysis,
-   scikit-learn for machine learning algorithms and model evaluation,
-   matplotlib and seaborn for visualization, and
-   Jupyter Notebook as the development environment.

Data preprocessing, training, and evaluation will be done locally using standard computing resources. The software selection ensures flexibility, reproducibility, and transparency of the research workflow.

#### Ethical Considerations

Since the dataset used in this study is publicly available and fully anonymized, there are no direct ethical risks related to privacy or patient confidentiality. Nevertheless, the research will ensure responsible interpretation of results. The predictive models developed are intended solely for educational and research purposes and should not be applied to real-world clinical diagnosis without appropriate professional validation. Ethical research practice also involves proper acknowledgment of data sources, minimizing potential bias in model design, and maintaining transparency in the reporting of methods and results.

### Results

#### Presentation of Data

The dataset consisted of 303 patient records with 14 clinical features, including age, sex, resting blood pressure, cholesterol, fasting blood sugar, maximum heart rate achieved, and others. The target variable, presence of heart disease, was binary (1 = disease, 0 = no disease).

After preprocessing and ensuring all features were standardized, the dataset was split into 80% training and 20% testing subsets using stratified sampling. No missing values were present. Figure 1 shows the correlation heatmap between the numerical features and the target variable.

Strong correlations were observed between maximum heart rate achieved (thalach) and the absence of heart disease, while chest pain type (cp) and ST depression (oldpeak) showed higher correlation with disease presence. Weak to moderate positive correlations existed between age, cholesterol, and presence of heart disease, aligning with known cardiovascular risk factors.

![](images/Screenshot 2025-10-29 at 7.27.00 PM-02.png){fig-align="center"}

#### Model Performance and Evaluation

Four supervised learning models were trained and evaluated: Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine (SVM). Model performance was assessed on accuracy, precision, recall, F1-score, and area under the ROC curve (AUC).

Random Forest achieved the highest overall accuracy (90.16%) and AUC (0.956), outperforming other models in recall and balanced F1-score. The Logistic Regression model performed consistently well, with slightly lower accuracy but nearly identical AUC, demonstrating strong predictive power with interpretability advantages. The SVM achieved high recall but slightly reduced precision, while the Decision Tree model underperformed, likely due to overfitting on the small dataset. Figure 2 presents the ROC curves for all models, confirming the superior discriminative performance of Random Forest and Logistic Regression. Figure 3 shows the confusion matrices, illustrating that Random Forest had the fewest false negatives, which is clinically significant since minimizing missed cases of heart disease is critical.

![](images/Screenshot%202025-10-29%20at%207.34.03%20PM-02.png){fig-align="center" width="500"}

![](images/Screenshot%202025-10-29%20at%207.34.12%20PM-01.png){fig-align="center" width="400"}

| Model               | Accuracy | Precision | Recall | F1-score | AUC    |
|---------------------|----------|-----------|--------|----------|--------|
| Random Forest       | 0.9016   | 0.8438    | 0.9643 | 0.9000   | 0.9556 |
| Logistic Regression | 0.8689   | 0.8125    | 0.9286 | 0.8667   | 0.9535 |
| SVM                 | 0.8525   | 0.8065    | 0.8929 | 0.8475   | 0.9475 |
| Decision Tree       | 0.7213   | 0.6571    | 0.8214 | 0.7302   | 0.7289 |

#### Comparison with Expected Outcomes

The results are consistent with expectations and prior research indicating that ensemble models such as Random Forest typically outperform single classifiers in medical prediction tasks due to their robustness and reduced variance. Logistic Regression was expected to perform well given the linear nature of many health risk relationships, and it did. The lower performance of the Decision Tree model was anticipated due to its sensitivity to small data variations.

#### Limitations of the Results

Although the models achieved high predictive accuracy, several limitations should be acknowledged: The dataset contained only 303 samples, which limits generalizability to larger or more diverse populations. The data were sourced from a single site (Cleveland Clinic Foundation), meaning demographic or regional differences were not accounted for. Certain models, particularly Decision Tree and SVM, may be sensitive to feature scaling and class distribution. External validation using an independent dataset was not performed, so real-world performance remains untested. Future work should focus on expanding dataset diversity, performing external validation, and integrating explainable AI (XAI) methods (e.g., SHAP, LIME) for deeper clinical interpretability.

#### Summary of Findings

In summary, the machine learning models demonstrated strong predictive capability for identifying heart disease. Random Forest emerged as the most effective model, achieving 90.16% accuracy and AUC = 0.956, while Logistic Regression provided a nearly equivalent, more interpretable alternative. The most significant predictors were chest pain type, maximum heart rate, ST depression, blood pressure, and age — variables that align with established cardiovascular risk factors. These findings confirm that data-driven predictive models can substantially enhance early heart disease detection and support medical decision-making when applied responsibly and validated clinically.

::: {align="right"}
Madhu Kiran Reddy Koduru
:::
